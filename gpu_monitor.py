#!/usr/bin/env python3
"""
GPU Burn æ¸¬è©¦ç›£æ§å·¥å…·
è‡ªå‹•å•Ÿå‹• gpu-burn ä¸¦è¨˜éŒ„ GPU æº«åº¦ã€è¨˜æ†¶é«”ã€ä½¿ç”¨ç‡ç­‰æŒ‡æ¨™ï¼Œç”¢ç”Ÿè¦–è¦ºåŒ–åœ–è¡¨

ä½¿ç”¨æ–¹å¼:
    python gpu_monitor.py --duration 300      # é‹è¡Œ gpu-burn ä¸¦ç›£æ§ 300 ç§’
    python gpu_monitor.py --duration 10m      # é‹è¡Œ gpu-burn ä¸¦ç›£æ§ 10 åˆ†é˜
    python gpu_monitor.py --duration 1h       # é‹è¡Œ gpu-burn ä¸¦ç›£æ§ 1 å°æ™‚
    python gpu_monitor.py --duration 300 --interval 0.5  # æ¯ 0.5 ç§’å–æ¨£ä¸€æ¬¡
    python gpu_monitor.py --duration 5m --no-burn        # åªç›£æ§ï¼Œä¸å•Ÿå‹• gpu-burn
    python gpu_monitor.py --duration 5m --gpu-burn-path /opt/gpu-burn/gpu_burn  # æŒ‡å®š gpu-burn è·¯å¾‘
"""

import subprocess
import time
import argparse
import csv
import sys
import os
import signal
import shutil
from datetime import datetime
from pathlib import Path
import threading

try:
    import matplotlib.pyplot as plt
    import matplotlib.dates as mdates
    from matplotlib.ticker import MaxNLocator
    HAS_MATPLOTLIB = True
except ImportError:
    HAS_MATPLOTLIB = False
    print("è­¦å‘Š: matplotlib æœªå®‰è£ï¼Œå°‡ç„¡æ³•ç”¢ç”Ÿåœ–è¡¨")
    print("å®‰è£æ–¹å¼: pip install matplotlib")


def parse_duration(duration_str: str) -> int:
    """è§£ææ™‚é–“å­—ä¸²ï¼Œæ”¯æ´ç§’(s)ã€åˆ†é˜(m)ã€å°æ™‚(h)æ ¼å¼"""
    duration_str = str(duration_str).strip().lower()
    
    if duration_str.endswith('h'):
        return int(float(duration_str[:-1]) * 3600)
    elif duration_str.endswith('m'):
        return int(float(duration_str[:-1]) * 60)
    elif duration_str.endswith('s'):
        return int(float(duration_str[:-1]))
    else:
        return int(float(duration_str))


def check_nvidia_smi() -> bool:
    """æª¢æŸ¥ nvidia-smi æ˜¯å¦å¯ç”¨"""
    try:
        subprocess.run(['nvidia-smi'], capture_output=True, check=True)
        return True
    except (subprocess.CalledProcessError, FileNotFoundError):
        return False


def find_gpu_burn() -> str:
    """å°‹æ‰¾ gpu-burn åŸ·è¡Œæª”è·¯å¾‘"""
    # å¸¸è¦‹è·¯å¾‘
    common_paths = [
        'gpu_burn',
        'gpu-burn',
        '/usr/local/bin/gpu_burn',
        '/usr/local/bin/gpu-burn',
        '/opt/gpu-burn/gpu_burn',
        '/opt/gpu_burn/gpu_burn',
        './gpu_burn',
        './gpu-burn',
    ]
    
    # å…ˆæª¢æŸ¥ PATH ä¸­æ˜¯å¦æœ‰
    for cmd in ['gpu_burn', 'gpu-burn']:
        path = shutil.which(cmd)
        if path:
            return path
    
    # æª¢æŸ¥å¸¸è¦‹è·¯å¾‘
    for path in common_paths:
        if os.path.isfile(path) and os.access(path, os.X_OK):
            return path
    
    return None


def start_gpu_burn(duration: int, gpu_burn_path: str = None, use_sudo: bool = True) -> subprocess.Popen:
    """å•Ÿå‹• gpu-burn ç¨‹åº"""
    if gpu_burn_path is None:
        gpu_burn_path = find_gpu_burn()
    
    if gpu_burn_path is None:
        print("âš ï¸  è­¦å‘Š: æ‰¾ä¸åˆ° gpu-burnï¼Œå°‡åªé€²è¡Œç›£æ§")
        print("   è«‹ç¢ºèª gpu-burn å·²å®‰è£ï¼Œæˆ–ä½¿ç”¨ --gpu-burn-path æŒ‡å®šè·¯å¾‘")
        print("   å®‰è£æ–¹å¼: git clone https://github.com/wilicc/gpu-burn && cd gpu-burn && make")
        return None
    
    # æ§‹å»ºå‘½ä»¤
    cmd = []
    if use_sudo:
        cmd.append('sudo')
    cmd.extend([gpu_burn_path, str(duration)])
    
    print(f"ğŸ”¥ å•Ÿå‹• gpu-burn: {' '.join(cmd)}")
    
    try:
        # ä½¿ç”¨ Popen åœ¨èƒŒæ™¯é‹è¡Œ
        process = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
            bufsize=1,
            preexec_fn=os.setsid if os.name != 'nt' else None
        )
        return process
    except Exception as e:
        print(f"âš ï¸  ç„¡æ³•å•Ÿå‹• gpu-burn: {e}")
        return None


def stop_gpu_burn(process: subprocess.Popen):
    """åœæ­¢ gpu-burn ç¨‹åº"""
    if process is None:
        return
    
    try:
        # å˜—è©¦å„ªé›…åœ°çµ‚æ­¢é€²ç¨‹çµ„
        if os.name != 'nt':
            os.killpg(os.getpgid(process.pid), signal.SIGTERM)
        else:
            process.terminate()
        
        # ç­‰å¾…æœ€å¤š 5 ç§’
        try:
            process.wait(timeout=5)
        except subprocess.TimeoutExpired:
            # å¼·åˆ¶çµ‚æ­¢
            if os.name != 'nt':
                os.killpg(os.getpgid(process.pid), signal.SIGKILL)
            else:
                process.kill()
            process.wait()
        
        print("ğŸ›‘ gpu-burn å·²åœæ­¢")
    except Exception as e:
        print(f"âš ï¸  åœæ­¢ gpu-burn æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")


class GpuBurnOutputReader(threading.Thread):
    """èƒŒæ™¯è®€å– gpu-burn è¼¸å‡ºçš„åŸ·è¡Œç·’"""
    def __init__(self, process: subprocess.Popen, output_path: Path):
        super().__init__(daemon=True)
        self.process = process
        self.output_file = output_path / "gpu_burn_output.log"
        self.lines = []
        self.running = True
    
    def run(self):
        try:
            with open(self.output_file, 'w') as f:
                for line in iter(self.process.stdout.readline, ''):
                    if not self.running:
                        break
                    if line:
                        self.lines.append(line.strip())
                        f.write(line)
                        f.flush()
        except Exception:
            pass
    
    def stop(self):
        self.running = False
    
    def get_last_lines(self, n: int = 3) -> list:
        return self.lines[-n:] if self.lines else []


def get_gpu_info() -> list[dict]:
    """ä½¿ç”¨ nvidia-smi å–å¾—æ‰€æœ‰ GPU çš„è©³ç´°è³‡è¨Š"""
    query_fields = [
        'index',
        'name',
        'temperature.gpu',
        'utilization.gpu',
        'utilization.memory',
        'memory.used',
        'memory.total',
        'memory.free',
        'power.draw',
        'power.limit',
        'clocks.current.graphics',
        'clocks.current.memory',
        'clocks.current.sm',
        'fan.speed',
        'pstate',
        'pcie.link.gen.current',
        'pcie.link.width.current',
    ]
    
    cmd = [
        'nvidia-smi',
        f'--query-gpu={",".join(query_fields)}',
        '--format=csv,noheader,nounits'
    ]
    
    try:
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        gpus = []
        
        for line in result.stdout.strip().split('\n'):
            if not line.strip():
                continue
                
            values = [v.strip() for v in line.split(',')]
            
            def safe_float(val, default=0.0):
                try:
                    if val in ['[N/A]', 'N/A', '[Not Supported]', 'Not Supported', '']:
                        return default
                    return float(val)
                except (ValueError, TypeError):
                    return default
            
            def safe_int(val, default=0):
                try:
                    if val in ['[N/A]', 'N/A', '[Not Supported]', 'Not Supported', '']:
                        return default
                    return int(float(val))
                except (ValueError, TypeError):
                    return default
            
            gpu = {
                'index': safe_int(values[0]),
                'name': values[1] if len(values) > 1 else 'Unknown',
                'temperature': safe_float(values[2]) if len(values) > 2 else 0,
                'gpu_utilization': safe_float(values[3]) if len(values) > 3 else 0,
                'memory_utilization': safe_float(values[4]) if len(values) > 4 else 0,
                'memory_used': safe_float(values[5]) if len(values) > 5 else 0,
                'memory_total': safe_float(values[6]) if len(values) > 6 else 0,
                'memory_free': safe_float(values[7]) if len(values) > 7 else 0,
                'power_draw': safe_float(values[8]) if len(values) > 8 else 0,
                'power_limit': safe_float(values[9]) if len(values) > 9 else 0,
                'clock_graphics': safe_int(values[10]) if len(values) > 10 else 0,
                'clock_memory': safe_int(values[11]) if len(values) > 11 else 0,
                'clock_sm': safe_int(values[12]) if len(values) > 12 else 0,
                'fan_speed': safe_float(values[13]) if len(values) > 13 else 0,
                'pstate': values[14] if len(values) > 14 else 'N/A',
                'pcie_gen': safe_int(values[15]) if len(values) > 15 else 0,
                'pcie_width': safe_int(values[16]) if len(values) > 16 else 0,
            }
            gpus.append(gpu)
        
        return gpus
    except subprocess.CalledProcessError as e:
        print(f"nvidia-smi åŸ·è¡ŒéŒ¯èª¤: {e}")
        return []


def format_time(seconds: int) -> str:
    """å°‡ç§’æ•¸æ ¼å¼åŒ–ç‚ºæ˜“è®€çš„æ™‚é–“å­—ä¸²"""
    if seconds < 60:
        return f"{seconds}s"
    elif seconds < 3600:
        m, s = divmod(seconds, 60)
        return f"{m}m {s}s"
    else:
        h, remainder = divmod(seconds, 3600)
        m, s = divmod(remainder, 60)
        return f"{h}h {m}m {s}s"


def print_status(gpu: dict, elapsed: int, total: int):
    """å°å‡ºå³æ™‚ç‹€æ…‹"""
    progress = elapsed / total * 100
    bar_width = 30
    filled = int(bar_width * elapsed / total)
    bar = 'â–ˆ' * filled + 'â–‘' * (bar_width - filled)
    
    # æ¸…é™¤ä¸Šä¸€è¡Œä¸¦å°å‡ºæ–°ç‹€æ…‹
    status_lines = [
        f"\r{'â”€' * 70}",
        f"  GPU {gpu['index']}: {gpu['name']}",
        f"  é€²åº¦: [{bar}] {progress:5.1f}% ({format_time(elapsed)} / {format_time(total)})",
        f"  ğŸŒ¡ï¸  æº«åº¦: {gpu['temperature']:5.1f}Â°C    âš¡ åŠŸè€—: {gpu['power_draw']:6.1f}W / {gpu['power_limit']:.0f}W",
        f"  ğŸ“Š GPUä½¿ç”¨ç‡: {gpu['gpu_utilization']:5.1f}%    ğŸ’¾ è¨˜æ†¶é«”: {gpu['memory_used']:.0f} / {gpu['memory_total']:.0f} MB ({gpu['memory_utilization']:.1f}%)",
        f"  ğŸ”§ æ™‚è„ˆ: Graphics {gpu['clock_graphics']} MHz | Memory {gpu['clock_memory']} MHz | SM {gpu['clock_sm']} MHz",
        f"  ğŸŒ€ é¢¨æ‰‡: {gpu['fan_speed']:.0f}%    ğŸ”Œ PCIe: Gen{gpu['pcie_gen']} x{gpu['pcie_width']}    State: {gpu['pstate']}",
    ]
    
    # ç§»åˆ°æœ€ä¸Šæ–¹ä¸¦å°å‡º
    print('\033[7A', end='')  # å‘ä¸Šç§»å‹• 7 è¡Œ
    for line in status_lines:
        print(f"\033[K{line}")  # æ¸…é™¤è©²è¡Œä¸¦å°å‡º


def monitor_gpus(duration: int, interval: float = 1.0, output_dir: str = None,
                 run_gpu_burn: bool = True, gpu_burn_path: str = None, 
                 use_sudo: bool = True) -> dict:
    """ç›£æ§ GPU ä¸¦è¨˜éŒ„æ•¸æ“šï¼Œå¯é¸æ“‡åŒæ™‚é‹è¡Œ gpu-burn"""
    if output_dir is None:
        output_dir = f"gpu_monitor_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    # åˆå§‹åŒ–è³‡æ–™çµæ§‹
    data = {
        'timestamps': [],
        'elapsed_seconds': [],
        'gpus': {}
    }
    
    # å–å¾— GPU æ•¸é‡
    initial_gpus = get_gpu_info()
    if not initial_gpus:
        print("éŒ¯èª¤: æ‰¾ä¸åˆ°ä»»ä½• GPU")
        return data
    
    num_gpus = len(initial_gpus)
    print(f"\nğŸ” åµæ¸¬åˆ° {num_gpus} å€‹ GPU:")
    for gpu in initial_gpus:
        print(f"   GPU {gpu['index']}: {gpu['name']}")
        data['gpus'][gpu['index']] = {
            'name': gpu['name'],
            'temperature': [],
            'gpu_utilization': [],
            'memory_utilization': [],
            'memory_used': [],
            'memory_total': gpu['memory_total'],
            'power_draw': [],
            'power_limit': gpu['power_limit'],
            'clock_graphics': [],
            'clock_memory': [],
            'clock_sm': [],
            'fan_speed': [],
        }
    
    print(f"\nğŸ“‹ ç›£æ§è¨­å®š:")
    print(f"   æŒçºŒæ™‚é–“: {format_time(duration)}")
    print(f"   å–æ¨£é–“éš”: {interval} ç§’")
    print(f"   è¼¸å‡ºç›®éŒ„: {output_path.absolute()}")
    print(f"   GPU Burn: {'å•Ÿç”¨' if run_gpu_burn else 'åœç”¨'}")
    
    # å•Ÿå‹• gpu-burn
    gpu_burn_process = None
    gpu_burn_reader = None
    
    if run_gpu_burn:
        gpu_burn_process = start_gpu_burn(duration, gpu_burn_path, use_sudo)
        if gpu_burn_process:
            gpu_burn_reader = GpuBurnOutputReader(gpu_burn_process, output_path)
            gpu_burn_reader.start()
            time.sleep(1)  # çµ¦ gpu-burn ä¸€é»å•Ÿå‹•æ™‚é–“
    
    print(f"\nğŸš€ é–‹å§‹ç›£æ§... (Ctrl+C å¯æå‰çµæŸ)\n")
    
    # é ç•™ç©ºé–“çµ¦ç‹€æ…‹é¡¯ç¤º
    for _ in range(7):
        print()
    
    start_time = time.time()
    samples = 0
    
    try:
        while True:
            current_time = time.time()
            elapsed = current_time - start_time
            
            if elapsed >= duration:
                break
            
            # æª¢æŸ¥ gpu-burn æ˜¯å¦é‚„åœ¨é‹è¡Œ
            if gpu_burn_process and gpu_burn_process.poll() is not None:
                # gpu-burn å·²çµæŸ
                pass
            
            # å–å¾— GPU è³‡è¨Š
            gpus = get_gpu_info()
            timestamp = datetime.now()
            
            data['timestamps'].append(timestamp)
            data['elapsed_seconds'].append(elapsed)
            
            for gpu in gpus:
                idx = gpu['index']
                if idx in data['gpus']:
                    data['gpus'][idx]['temperature'].append(gpu['temperature'])
                    data['gpus'][idx]['gpu_utilization'].append(gpu['gpu_utilization'])
                    data['gpus'][idx]['memory_utilization'].append(gpu['memory_utilization'])
                    data['gpus'][idx]['memory_used'].append(gpu['memory_used'])
                    data['gpus'][idx]['power_draw'].append(gpu['power_draw'])
                    data['gpus'][idx]['clock_graphics'].append(gpu['clock_graphics'])
                    data['gpus'][idx]['clock_memory'].append(gpu['clock_memory'])
                    data['gpus'][idx]['clock_sm'].append(gpu['clock_sm'])
                    data['gpus'][idx]['fan_speed'].append(gpu['fan_speed'])
            
            # é¡¯ç¤ºç¬¬ä¸€å€‹ GPU çš„ç‹€æ…‹
            if gpus:
                print_status(gpus[0], int(elapsed), duration)
            
            samples += 1
            
            # ç­‰å¾…ä¸‹ä¸€æ¬¡å–æ¨£
            next_sample_time = start_time + samples * interval
            sleep_time = next_sample_time - time.time()
            if sleep_time > 0:
                time.sleep(sleep_time)
                
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç›£æ§è¢«ä½¿ç”¨è€…ä¸­æ–·")
    finally:
        # åœæ­¢ gpu-burn
        if gpu_burn_reader:
            gpu_burn_reader.stop()
        if gpu_burn_process:
            stop_gpu_burn(gpu_burn_process)
    
    actual_duration = time.time() - start_time
    print(f"\n\nâœ… ç›£æ§å®Œæˆ!")
    print(f"   ç¸½å–æ¨£æ•¸: {samples}")
    print(f"   å¯¦éš›é‹è¡Œæ™‚é–“: {format_time(int(actual_duration))}")
    
    # å„²å­˜ CSV
    save_csv(data, output_path)
    
    # ç”¢ç”Ÿåœ–è¡¨
    if HAS_MATPLOTLIB:
        generate_charts(data, output_path)
    
    # é¡¯ç¤º gpu-burn æœ€å¾Œè¼¸å‡º
    if gpu_burn_reader and gpu_burn_reader.lines:
        print(f"\nğŸ“ gpu-burn è¼¸å‡ºå·²å„²å­˜è‡³: {output_path / 'gpu_burn_output.log'}")
    
    return data


def save_csv(data: dict, output_path: Path):
    """å„²å­˜æ•¸æ“šç‚º CSV æª”æ¡ˆ"""
    for gpu_idx, gpu_data in data['gpus'].items():
        csv_file = output_path / f"gpu_{gpu_idx}_data.csv"
        
        with open(csv_file, 'w', newline='') as f:
            writer = csv.writer(f)
            writer.writerow([
                'timestamp', 'elapsed_seconds', 'temperature_c', 
                'gpu_utilization_pct', 'memory_utilization_pct', 
                'memory_used_mb', 'power_draw_w',
                'clock_graphics_mhz', 'clock_memory_mhz', 'clock_sm_mhz',
                'fan_speed_pct'
            ])
            
            for i, ts in enumerate(data['timestamps']):
                writer.writerow([
                    ts.isoformat(),
                    f"{data['elapsed_seconds'][i]:.2f}",
                    gpu_data['temperature'][i],
                    gpu_data['gpu_utilization'][i],
                    gpu_data['memory_utilization'][i],
                    gpu_data['memory_used'][i],
                    gpu_data['power_draw'][i],
                    gpu_data['clock_graphics'][i],
                    gpu_data['clock_memory'][i],
                    gpu_data['clock_sm'][i],
                    gpu_data['fan_speed'][i],
                ])
        
        print(f"   ğŸ“ å·²å„²å­˜: {csv_file}")


def generate_charts(data: dict, output_path: Path):
    """ç”¢ç”Ÿè¦–è¦ºåŒ–åœ–è¡¨"""
    if not data['timestamps']:
        print("è­¦å‘Š: æ²’æœ‰è³‡æ–™å¯ä»¥ç¹ªè£½åœ–è¡¨")
        return
    
    # è¨­å®šä¸­æ–‡å­—é«” (å¦‚æœå¯ç”¨)
    plt.rcParams['font.family'] = ['DejaVu Sans', 'sans-serif']
    plt.rcParams['axes.unicode_minus'] = False
    
    elapsed_minutes = [s / 60 for s in data['elapsed_seconds']]
    
    for gpu_idx, gpu_data in data['gpus'].items():
        fig, axes = plt.subplots(3, 2, figsize=(14, 12))
        fig.suptitle(f'GPU {gpu_idx}: {gpu_data["name"]} - Performance Monitor', 
                     fontsize=14, fontweight='bold')
        
        # 1. æº«åº¦åœ–
        ax = axes[0, 0]
        ax.plot(elapsed_minutes, gpu_data['temperature'], 'r-', linewidth=1.5, label='Temperature')
        ax.fill_between(elapsed_minutes, gpu_data['temperature'], alpha=0.3, color='red')
        ax.set_ylabel('Temperature (Â°C)')
        ax.set_xlabel('Time (minutes)')
        ax.set_title('GPU Temperature')
        ax.grid(True, alpha=0.3)
        ax.set_ylim(bottom=0)
        
        # æ¨™è¨»æœ€é«˜æº«åº¦
        max_temp = max(gpu_data['temperature'])
        max_temp_idx = gpu_data['temperature'].index(max_temp)
        ax.annotate(f'Max: {max_temp:.1f}Â°C', 
                    xy=(elapsed_minutes[max_temp_idx], max_temp),
                    xytext=(10, 10), textcoords='offset points',
                    fontsize=9, color='red',
                    arrowprops=dict(arrowstyle='->', color='red', lw=0.5))
        
        # 2. GPU ä½¿ç”¨ç‡åœ–
        ax = axes[0, 1]
        ax.plot(elapsed_minutes, gpu_data['gpu_utilization'], 'g-', linewidth=1.5)
        ax.fill_between(elapsed_minutes, gpu_data['gpu_utilization'], alpha=0.3, color='green')
        ax.set_ylabel('Utilization (%)')
        ax.set_xlabel('Time (minutes)')
        ax.set_title('GPU Utilization')
        ax.set_ylim(0, 105)
        ax.grid(True, alpha=0.3)
        
        avg_util = sum(gpu_data['gpu_utilization']) / len(gpu_data['gpu_utilization'])
        ax.axhline(y=avg_util, color='darkgreen', linestyle='--', alpha=0.7, label=f'Avg: {avg_util:.1f}%')
        ax.legend(loc='lower right')
        
        # 3. è¨˜æ†¶é«”ä½¿ç”¨åœ–
        ax = axes[1, 0]
        memory_gb = [m / 1024 for m in gpu_data['memory_used']]
        memory_total_gb = gpu_data['memory_total'] / 1024
        ax.plot(elapsed_minutes, memory_gb, 'b-', linewidth=1.5)
        ax.fill_between(elapsed_minutes, memory_gb, alpha=0.3, color='blue')
        ax.axhline(y=memory_total_gb, color='darkblue', linestyle='--', alpha=0.5, 
                   label=f'Total: {memory_total_gb:.1f} GB')
        ax.set_ylabel('Memory Used (GB)')
        ax.set_xlabel('Time (minutes)')
        ax.set_title('GPU Memory Usage')
        ax.set_ylim(0, memory_total_gb * 1.1)
        ax.grid(True, alpha=0.3)
        ax.legend(loc='lower right')
        
        # 4. åŠŸè€—åœ–
        ax = axes[1, 1]
        ax.plot(elapsed_minutes, gpu_data['power_draw'], 'orange', linewidth=1.5)
        ax.fill_between(elapsed_minutes, gpu_data['power_draw'], alpha=0.3, color='orange')
        if gpu_data['power_limit'] > 0:
            ax.axhline(y=gpu_data['power_limit'], color='red', linestyle='--', alpha=0.5,
                       label=f'Limit: {gpu_data["power_limit"]:.0f}W')
        ax.set_ylabel('Power Draw (W)')
        ax.set_xlabel('Time (minutes)')
        ax.set_title('Power Consumption')
        ax.set_ylim(bottom=0)
        ax.grid(True, alpha=0.3)
        ax.legend(loc='lower right')
        
        # 5. æ™‚è„ˆåœ–
        ax = axes[2, 0]
        ax.plot(elapsed_minutes, gpu_data['clock_graphics'], 'purple', linewidth=1.5, label='Graphics')
        ax.plot(elapsed_minutes, gpu_data['clock_sm'], 'magenta', linewidth=1.5, label='SM', alpha=0.7)
        ax.set_ylabel('Clock Speed (MHz)')
        ax.set_xlabel('Time (minutes)')
        ax.set_title('GPU Clock Speeds')
        ax.grid(True, alpha=0.3)
        ax.legend(loc='lower right')
        ax.set_ylim(bottom=0)
        
        # 6. é¢¨æ‰‡é€Ÿåº¦åœ–
        ax = axes[2, 1]
        ax.plot(elapsed_minutes, gpu_data['fan_speed'], 'cyan', linewidth=1.5)
        ax.fill_between(elapsed_minutes, gpu_data['fan_speed'], alpha=0.3, color='cyan')
        ax.set_ylabel('Fan Speed (%)')
        ax.set_xlabel('Time (minutes)')
        ax.set_title('Fan Speed')
        ax.set_ylim(0, 105)
        ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # å„²å­˜åœ–è¡¨
        chart_file = output_path / f"gpu_{gpu_idx}_chart.png"
        plt.savefig(chart_file, dpi=150, bbox_inches='tight', facecolor='white')
        plt.close()
        
        print(f"   ğŸ“Š å·²å„²å­˜åœ–è¡¨: {chart_file}")
    
    # ç”¢ç”Ÿç¶œåˆå ±å‘Šåœ–
    if len(data['gpus']) > 1:
        generate_summary_chart(data, output_path)


def generate_summary_chart(data: dict, output_path: Path):
    """ç”¢ç”Ÿå¤š GPU æ¯”è¼ƒåœ–"""
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    fig.suptitle('Multi-GPU Comparison', fontsize=14, fontweight='bold')
    
    elapsed_minutes = [s / 60 for s in data['elapsed_seconds']]
    colors = plt.cm.tab10(range(len(data['gpus'])))
    
    # æº«åº¦æ¯”è¼ƒ
    ax = axes[0, 0]
    for (gpu_idx, gpu_data), color in zip(data['gpus'].items(), colors):
        ax.plot(elapsed_minutes, gpu_data['temperature'], color=color, 
                linewidth=1.5, label=f'GPU {gpu_idx}')
    ax.set_ylabel('Temperature (Â°C)')
    ax.set_xlabel('Time (minutes)')
    ax.set_title('Temperature Comparison')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # ä½¿ç”¨ç‡æ¯”è¼ƒ
    ax = axes[0, 1]
    for (gpu_idx, gpu_data), color in zip(data['gpus'].items(), colors):
        ax.plot(elapsed_minutes, gpu_data['gpu_utilization'], color=color,
                linewidth=1.5, label=f'GPU {gpu_idx}')
    ax.set_ylabel('Utilization (%)')
    ax.set_xlabel('Time (minutes)')
    ax.set_title('GPU Utilization Comparison')
    ax.legend()
    ax.grid(True, alpha=0.3)
    ax.set_ylim(0, 105)
    
    # åŠŸè€—æ¯”è¼ƒ
    ax = axes[1, 0]
    for (gpu_idx, gpu_data), color in zip(data['gpus'].items(), colors):
        ax.plot(elapsed_minutes, gpu_data['power_draw'], color=color,
                linewidth=1.5, label=f'GPU {gpu_idx}')
    ax.set_ylabel('Power (W)')
    ax.set_xlabel('Time (minutes)')
    ax.set_title('Power Consumption Comparison')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # è¨˜æ†¶é«”æ¯”è¼ƒ
    ax = axes[1, 1]
    for (gpu_idx, gpu_data), color in zip(data['gpus'].items(), colors):
        memory_gb = [m / 1024 for m in gpu_data['memory_used']]
        ax.plot(elapsed_minutes, memory_gb, color=color,
                linewidth=1.5, label=f'GPU {gpu_idx}')
    ax.set_ylabel('Memory (GB)')
    ax.set_xlabel('Time (minutes)')
    ax.set_title('Memory Usage Comparison')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    summary_file = output_path / "multi_gpu_summary.png"
    plt.savefig(summary_file, dpi=150, bbox_inches='tight', facecolor='white')
    plt.close()
    
    print(f"   ğŸ“Š å·²å„²å­˜ç¶œåˆåœ–è¡¨: {summary_file}")


def print_summary(data: dict):
    """å°å‡ºçµ±è¨ˆæ‘˜è¦"""
    print("\n" + "=" * 70)
    print("ğŸ“ˆ çµ±è¨ˆæ‘˜è¦")
    print("=" * 70)
    
    for gpu_idx, gpu_data in data['gpus'].items():
        if not gpu_data['temperature']:
            continue
            
        print(f"\nğŸ–¥ï¸  GPU {gpu_idx}: {gpu_data['name']}")
        print("-" * 50)
        
        # æº«åº¦çµ±è¨ˆ
        temps = gpu_data['temperature']
        print(f"  æº«åº¦    : æœ€ä½ {min(temps):.1f}Â°C | å¹³å‡ {sum(temps)/len(temps):.1f}Â°C | æœ€é«˜ {max(temps):.1f}Â°C")
        
        # ä½¿ç”¨ç‡çµ±è¨ˆ
        utils = gpu_data['gpu_utilization']
        print(f"  GPUä½¿ç”¨ç‡: æœ€ä½ {min(utils):.1f}% | å¹³å‡ {sum(utils)/len(utils):.1f}% | æœ€é«˜ {max(utils):.1f}%")
        
        # è¨˜æ†¶é«”çµ±è¨ˆ
        mems = gpu_data['memory_used']
        print(f"  è¨˜æ†¶é«”  : æœ€ä½ {min(mems):.0f}MB | å¹³å‡ {sum(mems)/len(mems):.0f}MB | æœ€é«˜ {max(mems):.0f}MB")
        
        # åŠŸè€—çµ±è¨ˆ
        powers = gpu_data['power_draw']
        print(f"  åŠŸè€—    : æœ€ä½ {min(powers):.1f}W | å¹³å‡ {sum(powers)/len(powers):.1f}W | æœ€é«˜ {max(powers):.1f}W")
        
        # é¢¨æ‰‡çµ±è¨ˆ
        fans = gpu_data['fan_speed']
        if any(f > 0 for f in fans):
            print(f"  é¢¨æ‰‡    : æœ€ä½ {min(fans):.0f}% | å¹³å‡ {sum(fans)/len(fans):.0f}% | æœ€é«˜ {max(fans):.0f}%")


def main():
    parser = argparse.ArgumentParser(
        description='GPU Burn æ¸¬è©¦ç›£æ§å·¥å…· - è‡ªå‹•å•Ÿå‹• gpu-burn ä¸¦ç›£æ§ GPU ç‹€æ…‹',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¯„ä¾‹:
  %(prog)s --duration 300           # é‹è¡Œ gpu-burn ä¸¦ç›£æ§ 300 ç§’
  %(prog)s --duration 10m           # é‹è¡Œ gpu-burn ä¸¦ç›£æ§ 10 åˆ†é˜
  %(prog)s --duration 1h            # é‹è¡Œ gpu-burn ä¸¦ç›£æ§ 1 å°æ™‚
  %(prog)s -d 5m -i 0.5             # æ¯ 0.5 ç§’å–æ¨£ï¼ŒæŒçºŒ 5 åˆ†é˜
  %(prog)s -d 30m -o my_test        # çµæœå­˜åˆ° my_test ç›®éŒ„
  %(prog)s -d 10m --no-burn         # åªç›£æ§ï¼Œä¸å•Ÿå‹• gpu-burn
  %(prog)s -d 5m --no-sudo          # ä¸ä½¿ç”¨ sudo åŸ·è¡Œ gpu-burn
  %(prog)s -d 5m --gpu-burn-path /opt/gpu-burn/gpu_burn  # æŒ‡å®š gpu-burn è·¯å¾‘
        """
    )
    
    parser.add_argument('-d', '--duration', type=str, required=True,
                        help='ç›£æ§æŒçºŒæ™‚é–“ (æ”¯æ´æ ¼å¼: 300, 300s, 10m, 1h)')
    parser.add_argument('-i', '--interval', type=float, default=1.0,
                        help='å–æ¨£é–“éš”ï¼Œå–®ä½ç§’ (é è¨­: 1.0)')
    parser.add_argument('-o', '--output', type=str, default=None,
                        help='è¼¸å‡ºç›®éŒ„åç¨± (é è¨­: gpu_monitor_YYYYMMDD_HHMMSS)')
    parser.add_argument('--no-burn', action='store_true',
                        help='ä¸å•Ÿå‹• gpu-burnï¼Œåªé€²è¡Œç›£æ§')
    parser.add_argument('--no-sudo', action='store_true',
                        help='ä¸ä½¿ç”¨ sudo åŸ·è¡Œ gpu-burn')
    parser.add_argument('--gpu-burn-path', type=str, default=None,
                        help='æŒ‡å®š gpu-burn åŸ·è¡Œæª”è·¯å¾‘')
    
    args = parser.parse_args()
    
    # æª¢æŸ¥ nvidia-smi
    if not check_nvidia_smi():
        print("éŒ¯èª¤: nvidia-smi ä¸å¯ç”¨ï¼Œè«‹ç¢ºèªå·²å®‰è£ NVIDIA é©…å‹•ç¨‹å¼")
        sys.exit(1)
    
    # è§£ææ™‚é–“
    try:
        duration = parse_duration(args.duration)
    except ValueError:
        print(f"éŒ¯èª¤: ç„¡æ•ˆçš„æ™‚é–“æ ¼å¼ '{args.duration}'")
        sys.exit(1)
    
    if duration <= 0:
        print("éŒ¯èª¤: æŒçºŒæ™‚é–“å¿…é ˆå¤§æ–¼ 0")
        sys.exit(1)
    
    if args.interval <= 0:
        print("éŒ¯èª¤: å–æ¨£é–“éš”å¿…é ˆå¤§æ–¼ 0")
        sys.exit(1)
    
    # é–‹å§‹ç›£æ§
    print("\n" + "=" * 70)
    print("ğŸ”¥ GPU Burn æ¸¬è©¦ç›£æ§å·¥å…·")
    print("=" * 70)
    
    data = monitor_gpus(
        duration=duration,
        interval=args.interval,
        output_dir=args.output,
        run_gpu_burn=not args.no_burn,
        gpu_burn_path=args.gpu_burn_path,
        use_sudo=not args.no_sudo
    )
    
    # å°å‡ºçµ±è¨ˆæ‘˜è¦
    print_summary(data)
    
    print("\n" + "=" * 70)
    print("âœ… ç›£æ§å®Œæˆ!")
    print("=" * 70 + "\n")


if __name__ == '__main__':
    main()
